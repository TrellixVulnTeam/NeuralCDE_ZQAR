{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2484701",
   "metadata": {},
   "source": [
    "# experiments/models/metamodel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c3321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import torchdiffeq\n",
    "import torch\n",
    "import sklearn.model_selection\n",
    "import controldiffeq\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import collections as co\n",
    "import statistics\n",
    "import controldiffeq\n",
    "import sklearn.metrics\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c635d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here = pathlib.Path(\"./models/metamodel.py\")\n",
    "#sys.path.append(str(here / '..' / '..'))\n",
    "\n",
    "\n",
    "\n",
    "class NeuralCDE(torch.nn.Module):\n",
    "    \"\"\"A Neural CDE model. Provides a wrapper around the lower-level cdeint function, to get a flexible Neural CDE\n",
    "    model.\n",
    "\n",
    "    Specifically, considering the CDE\n",
    "    ```\n",
    "    z_t = z_{t_0} + \\int_{t_0}^t f(z_s)dX_s\n",
    "    ```\n",
    "    where X is determined by the data, and given some terminal time t_N, then this model first computes z_{t_N}, then\n",
    "    performs a linear function on it, and then outputs the result.\n",
    "\n",
    "    It's known that linear functions on CDEs are universal approximators, so this is a very general type of model.\n",
    "    \"\"\"\n",
    "    def __init__(self, func, input_channels, hidden_channels, output_channels, initial=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            func: As cdeint.\n",
    "            input_channels: How many channels there are in the input.\n",
    "            hidden_channels: The number of hidden channels, i.e. the size of z_t.\n",
    "            output_channels: How many channels to perform a linear map to at the end.\n",
    "            initial: Whether to automatically construct the initial value from data (in which case z0 must not be passed\n",
    "                during forward()), or to use the one supplied during forward (in which case z0 must be passed during\n",
    "                forward()).\n",
    "        \"\"\"\n",
    "        if isinstance(func, ContinuousRNNConverter):  # ugly hack\n",
    "            hidden_channels = hidden_channels + input_channels\n",
    "\n",
    "        super(NeuralCDE, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.func = func\n",
    "        self.initial = initial\n",
    "        if initial and not isinstance(func, ContinuousRNNConverter):  # very ugly hack\n",
    "            self.initial_network = torch.nn.Linear(input_channels, hidden_channels)\n",
    "        self.linear = torch.nn.Linear(hidden_channels, output_channels)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels={}, hidden_channels={}, output_channels={}, initial={}\" \\\n",
    "               \"\".format(self.input_channels, self.hidden_channels, self.output_channels, self.initial)\n",
    "\n",
    "    def forward(self, times, coeffs, final_index, z0=None, stream=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            times: The times of the observations for the input path X, e.g. as passed as an argument to\n",
    "                `controldiffeq.natural_cubic_spline_coeffs`.\n",
    "            coeffs: The coefficients describing the input path X, e.g. as returned by\n",
    "                `controldiffeq.natural_cubic_spline_coeffs`.\n",
    "            final_index: Each batch element may have a different final time. This defines the index within the tensor\n",
    "                `times` of where the final time for each batch element is.\n",
    "            z0: See the 'initial' argument to __init__.\n",
    "            stream: Whether to return the result of the Neural CDE model at all times (True), or just the final time\n",
    "                (False). Defaults to just the final time. The `final_index` argument is ignored if stream is True.\n",
    "            **kwargs: Will be passed to cdeint.\n",
    "\n",
    "        Returns:\n",
    "            If stream is False, then this will return the terminal time z_T. If stream is True, then this will return\n",
    "            all intermediate times z_t, for those t for which there was data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the sizes of the batch dimensions from the coefficients\n",
    "        coeff, _, _, _ = coeffs\n",
    "        batch_dims = coeff.shape[:-2]\n",
    "        if not stream:\n",
    "            assert batch_dims == final_index.shape, \"coeff.shape[:-2] must be the same as final_index.shape. \" \\\n",
    "                                                    \"coeff.shape[:-2]={}, final_index.shape={}\" \\\n",
    "                                                    \"\".format(batch_dims, final_index.shape)\n",
    "\n",
    "        cubic_spline = controldiffeq.NaturalCubicSpline(times, coeffs)\n",
    "\n",
    "        if z0 is None:\n",
    "            assert self.initial, \"Was not expecting to be given no value of z0.\"\n",
    "            if isinstance(self.func, ContinuousRNNConverter):  # still an ugly hack\n",
    "                z0 = torch.zeros(*batch_dims, self.hidden_channels, dtype=coeff.dtype, device=coeff.device)\n",
    "            else:\n",
    "                z0 = self.initial_network(cubic_spline.evaluate(times[0]))\n",
    "        else:\n",
    "            assert not self.initial, \"Was expecting to be given a value of z0.\"\n",
    "            if isinstance(self.func, ContinuousRNNConverter):  # continuing adventures in ugly hacks\n",
    "                z0_extra = torch.zeros(*batch_dims, self.input_channels, dtype=z0.dtype, device=z0.device)\n",
    "                z0 = torch.cat([z0_extra, z0], dim=-1)\n",
    "\n",
    "        # Figure out what times we need to solve for\n",
    "        if stream:\n",
    "            t = times\n",
    "        else:\n",
    "            # faff around to make sure that we're outputting at all the times we need for final_index.\n",
    "            sorted_final_index, inverse_final_index = final_index.unique(sorted=True, return_inverse=True)\n",
    "            if 0 in sorted_final_index:\n",
    "                sorted_final_index = sorted_final_index[1:]\n",
    "                final_index = inverse_final_index\n",
    "            else:\n",
    "                final_index = inverse_final_index + 1\n",
    "            if len(times) - 1 in sorted_final_index:\n",
    "                sorted_final_index = sorted_final_index[:-1]\n",
    "            t = torch.cat([times[0].unsqueeze(0), times[sorted_final_index], times[-1].unsqueeze(0)])\n",
    "\n",
    "        # Switch default solver\n",
    "        if 'method' not in kwargs:\n",
    "            kwargs['method'] = 'rk4'\n",
    "        if kwargs['method'] == 'rk4':\n",
    "            if 'options' not in kwargs:\n",
    "                kwargs['options'] = {}\n",
    "            options = kwargs['options']\n",
    "            if 'step_size' not in options and 'grid_constructor' not in options:\n",
    "                time_diffs = times[1:] - times[:-1]\n",
    "                options['step_size'] = time_diffs.min().item()\n",
    "\n",
    "        # Actually solve the CDE\n",
    "        z_t = controldiffeq.cdeint(dX_dt=cubic_spline.derivative,\n",
    "                                   z0=z0,\n",
    "                                   func=self.func,\n",
    "                                   t=t,\n",
    "                                   **kwargs)\n",
    "\n",
    "        # Organise the output\n",
    "        if stream:\n",
    "            # z_t is a tensor of shape (times, ..., channels), so change this to (..., times, channels)\n",
    "            for i in range(len(z_t.shape) - 2, 0, -1):\n",
    "                z_t = z_t.transpose(0, i)\n",
    "        else:\n",
    "            # final_index is a tensor of shape (...)\n",
    "            # z_t is a tensor of shape (times, ..., channels)\n",
    "            final_index_indices = final_index.unsqueeze(-1).expand(z_t.shape[1:]).unsqueeze(0)\n",
    "            z_t = z_t.gather(dim=0, index=final_index_indices).squeeze(0)\n",
    "\n",
    "        # Linear map and return\n",
    "        pred_y = self.linear(z_t)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "# Note that this relies on the first channel being time\n",
    "class ContinuousRNNConverter(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, model):\n",
    "        super(ContinuousRNNConverter, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.model = model\n",
    "\n",
    "        out_base = torch.zeros(self.input_channels + self.hidden_channels, self.input_channels)\n",
    "        for i in range(self.input_channels):\n",
    "            out_base[i, i] = 1\n",
    "        self.register_buffer('out_base', out_base)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels: {}, hidden_channels: {}\".format(self.input_channels, self.hidden_channels)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z is a tensor of shape (..., input_channels + hidden_channels)\n",
    "        x = z[..., :self.input_channels]\n",
    "        h = z[..., self.input_channels:]\n",
    "        # In theory the hidden state must lie in this region. And most of the time it does anyway! Very occasionally\n",
    "        # it escapes this and breaks everything, though. (Even when using adaptive solvers or small step sizes.) Which\n",
    "        # is kind of surprising given how similar the GRU-ODE is to a standard negative exponential problem, we'd\n",
    "        # expect to get absolute stability without too much difficulty. Maybe there's a bug in the implementation\n",
    "        # somewhere, but not that I've been able to find... (and h does only escape this region quite rarely.)\n",
    "        h = h.clamp(-1, 1)\n",
    "        # model_out is a tensor of shape (..., hidden_channels)\n",
    "        model_out = self.model(x, h)\n",
    "        batch_dims = model_out.shape[:-1]\n",
    "        out = self.out_base.repeat(*batch_dims, 1, 1).clone()\n",
    "        out[..., self.input_channels:, 0] = model_out\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202e23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _GRU(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, use_intensity):\n",
    "        super(_GRU, self).__init__()\n",
    "\n",
    "        assert (input_channels % 2) == 1, \"Input channels must be odd: 1 for time, plus 1 for each actual input, \" \\\n",
    "                                          \"plus 1 for whether an observation was made for the actual input.\"\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.use_intensity = use_intensity\n",
    "\n",
    "        gru_channels = input_channels if use_intensity else (input_channels - 1) // 2\n",
    "        self.gru_cell = torch.nn.GRUCell(input_size=gru_channels, hidden_size=hidden_channels)\n",
    "        self.linear = torch.nn.Linear(hidden_channels, output_channels)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels={}, hidden_channels={}, output_channels={}, use_intensity={}\" \\\n",
    "               \"\".format(self.input_channels, self.hidden_channels, self.output_channels, self.use_intensity)\n",
    "\n",
    "    def evolve(self, h, time_diff):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _step(self, Xi, h, dt, half_num_channels):\n",
    "        observation = Xi[:, 1: 1 + half_num_channels].max(dim=1).values > 0.5\n",
    "        if observation.any():\n",
    "            Xi_piece = Xi if self.use_intensity else Xi[:, 1 + half_num_channels:]\n",
    "            Xi_piece = Xi_piece.clone()\n",
    "            Xi_piece[:, 0] += dt\n",
    "            new_h = self.gru_cell(Xi_piece, h)\n",
    "            h = torch.where(observation.unsqueeze(1), new_h, h)\n",
    "            dt += torch.where(observation, torch.tensor(0., dtype=Xi.dtype, device=Xi.device), Xi[:, 0])\n",
    "        return h, dt\n",
    "\n",
    "    def forward(self, times, coeffs, final_index, z0=None):\n",
    "        interp = controldiffeq.NaturalCubicSpline(times, coeffs)\n",
    "        X = torch.stack([interp.evaluate(t) for t in times], dim=-2)\n",
    "        half_num_channels = (self.input_channels - 1) // 2\n",
    "\n",
    "        # change cumulative intensity into intensity i.e. was an observation made or not, which is what is typically\n",
    "        # used here\n",
    "        X[:, 1:, 1:1 + half_num_channels] -= X[:, :-1, 1:1 + half_num_channels]\n",
    "\n",
    "        # change times into delta-times\n",
    "        X[:, 0, 0] -= times[0]\n",
    "        X[:, 1:, 0] -= times[:-1]\n",
    "\n",
    "        batch_dims = X.shape[:-2]\n",
    "\n",
    "        if z0 is None:\n",
    "            z0 = torch.zeros(*batch_dims, self.hidden_channels, dtype=X.dtype, device=X.device)\n",
    "\n",
    "        X_unbound = X.unbind(dim=1)\n",
    "        h, dt = self._step(X_unbound[0], z0, torch.zeros(*batch_dims, dtype=X.dtype, device=X.device),\n",
    "                           half_num_channels)\n",
    "        hs = [h]\n",
    "        time_diffs = times[1:] - times[:-1]\n",
    "        for time_diff, Xi in zip(time_diffs, X_unbound[1:]):\n",
    "            h = self.evolve(h, time_diff)\n",
    "            h, dt = self._step(Xi, h, dt, half_num_channels)\n",
    "            hs.append(h)\n",
    "        out = torch.stack(hs, dim=1)\n",
    "\n",
    "        final_index_indices = final_index.unsqueeze(-1).expand(out.size(0), out.size(2)).unsqueeze(1)\n",
    "        final_out = out.gather(dim=1, index=final_index_indices).squeeze(1)\n",
    "\n",
    "        return self.linear(final_out)\n",
    "\n",
    "\n",
    "class GRU_dt(_GRU):\n",
    "    def evolve(self, h, time_diff):\n",
    "        return h\n",
    "\n",
    "\n",
    "class GRU_D(_GRU):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, use_intensity):\n",
    "        super(GRU_D, self).__init__(input_channels=input_channels,\n",
    "                                    hidden_channels=hidden_channels,\n",
    "                                    output_channels=output_channels,\n",
    "                                    use_intensity=use_intensity)\n",
    "        self.decay = torch.nn.Linear(1, hidden_channels)\n",
    "\n",
    "    def evolve(self, h, time_diff):\n",
    "        return h * torch.exp(-self.decay(time_diff.unsqueeze(0)).squeeze(0).relu())\n",
    "\n",
    "\n",
    "class _ODERNNFunc(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, hidden_hidden_channels, num_hidden_layers):\n",
    "        super(_ODERNNFunc, self).__init__()\n",
    "\n",
    "        layers = [torch.nn.Linear(hidden_channels, hidden_hidden_channels)]\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layers.append(torch.nn.Tanh())\n",
    "            layers.append(torch.nn.Linear(hidden_hidden_channels, hidden_hidden_channels))\n",
    "        layers.append(torch.nn.Tanh())\n",
    "        layers.append(torch.nn.Linear(hidden_hidden_channels, hidden_channels))\n",
    "        self.sequential = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class ODERNN(_GRU):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, hidden_hidden_channels, num_hidden_layers,\n",
    "                 use_intensity):\n",
    "        super(ODERNN, self).__init__(input_channels=input_channels,\n",
    "                                     hidden_channels=hidden_channels,\n",
    "                                     output_channels=output_channels,\n",
    "                                     use_intensity=use_intensity)\n",
    "        self.hidden_hidden_channels = hidden_hidden_channels\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.func = _ODERNNFunc(hidden_channels, hidden_hidden_channels, num_hidden_layers)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"hidden_hidden_channels={}, num_hidden_layers={}\".format(self.hidden_hidden_channels,\n",
    "                                                                        self.num_hidden_layers)\n",
    "\n",
    "    def evolve(self, h, time_diff):\n",
    "        t = torch.tensor([0, time_diff.item()], dtype=time_diff.dtype, device=time_diff.device)\n",
    "        out = torchdiffeq.odeint_adjoint(func=self.func, y0=h, t=t, method='rk4')\n",
    "        return out[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9315a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHiddenLayer(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        super(SingleHiddenLayer, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, 128)\n",
    "        self.linear2 = torch.nn.Linear(128, input_channels * hidden_channels)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels: {}, hidden_channels: {}\".format(self.input_channels, self.hidden_channels)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.linear1(z)\n",
    "        z = torch.relu(z)\n",
    "        z = self.linear2(z)\n",
    "        z = z.view(*z.shape[:-1], self.hidden_channels, self.input_channels)\n",
    "        return z\n",
    "\n",
    "\n",
    "class FinalTanh(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, hidden_hidden_channels, num_hidden_layers):\n",
    "        super(FinalTanh, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.hidden_hidden_channels = hidden_hidden_channels\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "        self.linear_in = torch.nn.Linear(hidden_channels, hidden_hidden_channels)\n",
    "        self.linears = torch.nn.ModuleList(torch.nn.Linear(hidden_hidden_channels, hidden_hidden_channels)\n",
    "                                           for _ in range(num_hidden_layers - 1))\n",
    "        self.linear_out = torch.nn.Linear(hidden_hidden_channels, input_channels * hidden_channels)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels: {}, hidden_channels: {}, hidden_hidden_channels: {}, num_hidden_layers: {}\" \\\n",
    "               \"\".format(self.input_channels, self.hidden_channels, self.hidden_hidden_channels, self.num_hidden_layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = self.linear_in(z)\n",
    "        z = z.relu()\n",
    "        for linear in self.linears:\n",
    "            z = linear(z)\n",
    "            z = z.relu()\n",
    "        z = self.linear_out(z).view(*z.shape[:-1], self.hidden_channels, self.input_channels)\n",
    "        z = z.tanh()\n",
    "        return z\n",
    "\n",
    "\n",
    "class _GRU_ODE(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels):\n",
    "        super(_GRU_ODE, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "\n",
    "        self.W_r = torch.nn.Linear(input_channels, hidden_channels, bias=False)\n",
    "        self.W_z = torch.nn.Linear(input_channels, hidden_channels, bias=False)\n",
    "        self.W_h = torch.nn.Linear(input_channels, hidden_channels, bias=False)\n",
    "        self.U_r = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.U_z = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.U_h = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"input_channels: {}, hidden_channels: {}\".format(self.input_channels, self.hidden_channels)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        r = self.W_r(x) + self.U_r(h)\n",
    "        r = r.sigmoid()\n",
    "        z = self.W_z(x) + self.U_z(h)\n",
    "        z = z.sigmoid()\n",
    "        g = self.W_h(x) + self.U_h(r * h)\n",
    "        g = g.tanh()\n",
    "        return (1 - z) * (g - h)\n",
    "\n",
    "\n",
    "def GRU_ODE(input_channels, hidden_channels):\n",
    "    func = _GRU_ODE(input_channels=input_channels, hidden_channels=hidden_channels)\n",
    "    return metamodel.ContinuousRNNConverter(input_channels=input_channels,\n",
    "                                            hidden_channels=hidden_channels,\n",
    "                                            model=func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a89b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(dataset, **kwargs):\n",
    "    \n",
    "    print(\"_dataloader  function\")\n",
    "    if 'shuffle' not in kwargs:\n",
    "        kwargs['shuffle'] = True\n",
    "    if 'drop_last' not in kwargs:\n",
    "        kwargs['drop_last'] = True\n",
    "    if 'batch_size' not in kwargs:\n",
    "        kwargs['batch_size'] = 32\n",
    "    if 'num_workers' not in kwargs:\n",
    "        kwargs['num_workers'] = 8\n",
    "    kwargs['batch_size'] = min(kwargs['batch_size'], len(dataset))\n",
    "\n",
    "    return torch.utils.data.DataLoader(dataset, **kwargs)\n",
    "\n",
    "\n",
    "def split_data(tensor, stratify):\n",
    "    # 0.7/0.15/0.15 train/val/test split\n",
    "    print(\"split_data  function start before run\")\n",
    "\n",
    "    (train_tensor, testval_tensor,\n",
    "     train_stratify, testval_stratify) = sklearn.model_selection.train_test_split(tensor, stratify,\n",
    "                                                                                  train_size=0.7,\n",
    "                                                                                  random_state=0,\n",
    "                                                                                  shuffle=True,\n",
    "                                                                                  stratify=stratify)\n",
    "\n",
    "    val_tensor, test_tensor = sklearn.model_selection.train_test_split(testval_tensor,\n",
    "                                                                       train_size=0.5,\n",
    "                                                                       random_state=1,\n",
    "                                                                       shuffle=True,\n",
    "                                                                       stratify=testval_stratify)\n",
    "    print(\"split_data  function end before return\")\n",
    "    return train_tensor, val_tensor, test_tensor\n",
    "\n",
    "\n",
    "def normalise_data(X, y):\n",
    "    print(\"normalise_data  function start before runn\")\n",
    "    train_X, _, _ = split_data(X, y)\n",
    "    out = []\n",
    "    for Xi, train_Xi in zip(X.unbind(dim=-1), train_X.unbind(dim=-1)):\n",
    "        train_Xi_nonan = train_Xi.masked_select(~torch.isnan(train_Xi))\n",
    "        mean = train_Xi_nonan.mean()  # compute statistics using only training data.\n",
    "        std = train_Xi_nonan.std()\n",
    "        out.append((Xi - mean) / (std + 1e-5))\n",
    "    out = torch.stack(out, dim=-1)\n",
    "    print(\"normalise_data  function end before return\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def preprocess_data(times, X, y, final_index, append_times, append_intensity):\n",
    "    print(\"preprocess_data  function start before run\")\n",
    "    X = normalise_data(X, y)\n",
    "\n",
    "    # Append extra channels together. Note that the order here: time, intensity, original, is important, and some models\n",
    "    # depend on that order.\n",
    "    augmented_X = []\n",
    "    if append_times:\n",
    "        augmented_X.append(times.unsqueeze(0).repeat(X.size(0), 1).unsqueeze(-1))\n",
    "    if append_intensity:\n",
    "        intensity = ~torch.isnan(X)  # of size (batch, stream, channels)\n",
    "        intensity = intensity.to(X.dtype).cumsum(dim=1)\n",
    "        augmented_X.append(intensity)\n",
    "    augmented_X.append(X)\n",
    "    if len(augmented_X) == 1:\n",
    "        X = augmented_X[0]\n",
    "    else:\n",
    "        X = torch.cat(augmented_X, dim=2)\n",
    "\n",
    "    train_X, val_X, test_X = split_data(X, y)\n",
    "    train_y, val_y, test_y = split_data(y, y)\n",
    "    train_final_index, val_final_index, test_final_index = split_data(final_index, y)\n",
    "\n",
    "    train_coeffs = controldiffeq.natural_cubic_spline_coeffs(times, train_X)\n",
    "    val_coeffs = controldiffeq.natural_cubic_spline_coeffs(times, val_X)\n",
    "    test_coeffs = controldiffeq.natural_cubic_spline_coeffs(times, test_X)\n",
    "\n",
    "    in_channels = X.size(-1)\n",
    "    print(\"preprocess_data  function end before return\")\n",
    "\n",
    "    return (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "            test_final_index, in_channels)\n",
    "\n",
    "\n",
    "def wrap_data(times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "              test_final_index, device, batch_size, num_workers=4):\n",
    "\n",
    "    print(\"wrap_data  function start before run\")\n",
    "    times = times.to(device)\n",
    "    train_coeffs = tuple(coeff.to(device) for coeff in train_coeffs)\n",
    "    val_coeffs = tuple(coeff.to(device) for coeff in val_coeffs)\n",
    "    test_coeffs = tuple(coeff.to(device) for coeff in test_coeffs)\n",
    "    train_y = train_y.to(device)\n",
    "    val_y = val_y.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "    train_final_index = train_final_index.to(device)\n",
    "    val_final_index = val_final_index.to(device)\n",
    "    test_final_index = test_final_index.to(device)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(*train_coeffs, train_y, train_final_index)\n",
    "    val_dataset = torch.utils.data.TensorDataset(*val_coeffs, val_y, val_final_index)\n",
    "    test_dataset = torch.utils.data.TensorDataset(*test_coeffs, test_y, test_final_index)\n",
    "\n",
    "    train_dataloader = dataloader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    val_dataloader = dataloader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataloader = dataloader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "    print(\"wrap_data  function end before return\")\n",
    "\n",
    "    return times, train_dataloader, val_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def save_data(dir, **tensors):\n",
    "    print(\"save_data  function start before run\")\n",
    "    for tensor_name, tensor_value in tensors.items():\n",
    "        torch.save(tensor_value, str(dir / tensor_name) + '.pt')\n",
    "\n",
    "    print(\"save_data  function end\")\n",
    "\n",
    "def load_data(dir):\n",
    "    print(\"load_data  function start before run\")\n",
    "    tensors = {}\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith('.pt'):\n",
    "            tensor_name = filename.split('.')[0]\n",
    "            tensor_value = torch.load(str(dir / filename))\n",
    "            tensors[tensor_name] = tensor_value\n",
    "    print(\"load_data function end before return\")\n",
    "    return tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8c5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "here = pathlib.Path(\"./datasets\")\n",
    "\n",
    "\n",
    "def download():\n",
    "    print(\"Download function\")\n",
    "    base_base_loc = here / 'data'\n",
    "    base_loc = base_base_loc / 'SpeechCommands'\n",
    "    loc = base_loc / 'speech_commands.tar.gz'\n",
    "    if os.path.exists(loc):\n",
    "        return\n",
    "    if not os.path.exists(base_base_loc):\n",
    "        os.mkdir(base_base_loc)\n",
    "    if not os.path.exists(base_loc):\n",
    "        os.mkdir(base_loc)\n",
    "    urllib.request.urlretrieve('http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz', loc)\n",
    "    with tarfile.open(loc, 'r') as f:\n",
    "        f.extractall(base_loc)\n",
    "    print(\"Download function end\")\n",
    "\n",
    "\n",
    "def _process_data(intensity_data):\n",
    "\n",
    "    print(\"_process data  function\")\n",
    "    base_loc = here / 'data' / 'SpeechCommands'\n",
    "    X = torch.empty(34975, 16000, 1)\n",
    "    y = torch.empty(34975, dtype=torch.long)\n",
    "\n",
    "    batch_index = 0\n",
    "    y_index = 0\n",
    "    for foldername in ('yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go'):\n",
    "        loc = base_loc / foldername\n",
    "        for filename in os.listdir(loc):\n",
    "            audio, _ = torchaudio.load(loc / filename, channels_first=False)  # for forward compatbility if they fix it\n",
    "            audio = audio / 2 ** 15  # Normalization argument doesn't seem to work so we do it manually.\n",
    "\n",
    "            # A few samples are shorter than the full length; for simplicity we discard them.\n",
    "            if len(audio) != 16000:\n",
    "                continue\n",
    "\n",
    "            X[batch_index] = audio\n",
    "            y[batch_index] = y_index\n",
    "            batch_index += 1\n",
    "        y_index += 1\n",
    "    assert batch_index == 34975, \"batch_index is {}\".format(batch_index)\n",
    "\n",
    "    X = torchaudio.transforms.MFCC(log_mels=True, n_mfcc=20,\n",
    "                                   melkwargs=dict(n_fft=200, n_mels=64))(X.squeeze(-1)).transpose(1, 2).detach()\n",
    "    # X is of shape (batch=34975, length=161, channels=20)\n",
    "\n",
    "    times = torch.linspace(0, X.size(1) - 1, X.size(1))\n",
    "    final_index = torch.tensor(X.size(1) - 1).repeat(X.size(0))\n",
    "\n",
    "    (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "     test_final_index, _) = preprocess_data(times, X, y, final_index, append_times=True,\n",
    "                                                   append_intensity=intensity_data)\n",
    "\n",
    "    print(\"_process data  function end\")\n",
    "    return (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "            test_final_index)\n",
    "\n",
    "\n",
    "def get_data(intensity_data, batch_size):\n",
    "    print(\"_get data   function\")\n",
    "\n",
    "    base_base_loc = here / 'processed_data'\n",
    "    loc = base_base_loc / ('speech_commands_with_mels' + ('_intensity' if intensity_data else ''))\n",
    "    if os.path.exists(loc):\n",
    "        tensors = load_data(loc)\n",
    "        times = tensors['times']\n",
    "        train_coeffs = tensors['train_a'], tensors['train_b'], tensors['train_c'], tensors['train_d']\n",
    "        val_coeffs = tensors['val_a'], tensors['val_b'], tensors['val_c'], tensors['val_d']\n",
    "        test_coeffs = tensors['test_a'], tensors['test_b'], tensors['test_c'], tensors['test_d']\n",
    "        train_y = tensors['train_y']\n",
    "        val_y = tensors['val_y']\n",
    "        test_y = tensors['test_y']\n",
    "        train_final_index = tensors['train_final_index']\n",
    "        val_final_index = tensors['val_final_index']\n",
    "        test_final_index = tensors['test_final_index']\n",
    "    else:\n",
    "        download()\n",
    "        (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "         test_final_index) = _process_data(intensity_data)\n",
    "        if not os.path.exists(base_base_loc):\n",
    "            os.mkdir(base_base_loc)\n",
    "        if not os.path.exists(loc):\n",
    "            os.mkdir(loc)\n",
    "        save_data(loc, times=times,\n",
    "                         train_a=train_coeffs[0], train_b=train_coeffs[1], train_c=train_coeffs[2],\n",
    "                         train_d=train_coeffs[3],\n",
    "                         val_a=val_coeffs[0], val_b=val_coeffs[1], val_c=val_coeffs[2], val_d=val_coeffs[3],\n",
    "                         test_a=test_coeffs[0], test_b=test_coeffs[1], test_c=test_coeffs[2], test_d=test_coeffs[3],\n",
    "                         train_y=train_y, val_y=val_y, test_y=test_y, train_final_index=train_final_index,\n",
    "                         val_final_index=val_final_index, test_final_index=test_final_index)\n",
    "\n",
    "    times, train_dataloader, val_dataloader, test_dataloader = wrap_data(times, train_coeffs, val_coeffs,\n",
    "                                                                                test_coeffs, train_y, val_y, test_y,\n",
    "                                                                                train_final_index, val_final_index,\n",
    "                                                                                test_final_index, 'cpu',\n",
    "                                                                                batch_size=batch_size)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"_process data  function end, before return\")\n",
    "    return times, train_dataloader, val_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0df82",
   "metadata": {},
   "source": [
    "### Note: Cell này là cell xử lý data của thằng sepsis, nếu anh muốn chạy cái cell này thì đổi từ markdown thành code và đổi cell trên từ code thành markdown là xong\n",
    "here = pathlib.Path(\"./datasets\")\n",
    "\n",
    "base_base_loc = here / 'data'\n",
    "base_loc = base_base_loc / 'sepsis'\n",
    "loc_Azip = base_loc / 'training_setA.zip'\n",
    "loc_Bzip = base_loc / 'training_setB.zip'\n",
    "\n",
    "\n",
    "def download():\n",
    "    if not os.path.exists(loc_Azip):\n",
    "        if not os.path.exists(base_base_loc):\n",
    "            os.mkdir(base_base_loc)\n",
    "        if not os.path.exists(base_loc):\n",
    "            os.mkdir(base_loc)\n",
    "        urllib.request.urlretrieve('https://archive.physionet.org/users/shared/challenge-2019/training_setA.zip',\n",
    "                                   str(loc_Azip))\n",
    "        urllib.request.urlretrieve('https://archive.physionet.org/users/shared/challenge-2019/training_setB.zip',\n",
    "                                   str(loc_Bzip))\n",
    "\n",
    "        with zipfile.ZipFile(loc_Azip, 'r') as f:\n",
    "            f.extractall(str(base_loc))\n",
    "        with zipfile.ZipFile(loc_Bzip, 'r') as f:\n",
    "            f.extractall(str(base_loc))\n",
    "        for folder in ('training', 'training_setB'):\n",
    "            for filename in os.listdir(base_loc / folder):\n",
    "                if os.path.exists(base_loc / filename):\n",
    "                    raise RuntimeError\n",
    "                os.rename(base_loc / folder / filename, base_loc / filename)\n",
    "\n",
    "\n",
    "def _process_data(static_intensity, time_intensity):\n",
    "    X_times = []\n",
    "    X_static = []\n",
    "    y = []\n",
    "    for filename in os.listdir(base_loc):\n",
    "        if filename.endswith('.psv'):\n",
    "            with open(base_loc / filename) as file:\n",
    "                time = []\n",
    "                label = 0.0\n",
    "                reader = csv.reader(file, delimiter='|')\n",
    "                reader = iter(reader)\n",
    "                next(reader)  # first line is headings\n",
    "                prev_iculos = 0\n",
    "                for line in reader:\n",
    "                    assert len(line) == 41\n",
    "                    *time_values, age, gender, unit1, unit2, hospadmtime, iculos, sepsislabel = line\n",
    "                    iculos = int(iculos)\n",
    "                    if iculos > 72:  # keep at most the first three days\n",
    "                        break\n",
    "                    for iculos_ in range(prev_iculos + 1, iculos):\n",
    "                        time.append([float('nan') for value in time_values])\n",
    "                    prev_iculos = iculos\n",
    "                    time.append([float(value) for value in time_values])\n",
    "                    label = max(label, float(sepsislabel))\n",
    "                unit1 = float(unit1)\n",
    "                unit2 = float(unit2)\n",
    "                unit1_obs = not math.isnan(unit1)\n",
    "                unit2_obs = not math.isnan(unit2)\n",
    "                if not unit1_obs:\n",
    "                    unit1 = 0.\n",
    "                if not unit2_obs:\n",
    "                    unit2 = 0.\n",
    "                hospadmtime = float(hospadmtime)\n",
    "                if math.isnan(hospadmtime):\n",
    "                    hospadmtime = 0.  # this only happens for one record\n",
    "                static = [float(age), float(gender), unit1, unit2, hospadmtime]\n",
    "                if static_intensity:\n",
    "                    static += [unit1_obs, unit2_obs]\n",
    "                if len(time) > 2:\n",
    "                    X_times.append(time)\n",
    "                    X_static.append(static)\n",
    "                    y.append(label)\n",
    "    final_indices = []\n",
    "    for time in X_times:\n",
    "        final_indices.append(len(time) - 1)\n",
    "    maxlen = max(final_indices) + 1\n",
    "    for time in X_times:\n",
    "        for _ in range(maxlen - len(time)):\n",
    "            time.append([float('nan') for value in time_values])\n",
    "\n",
    "    X_times = torch.tensor(X_times)\n",
    "    X_static = torch.tensor(X_static)\n",
    "    y = torch.tensor(y)\n",
    "    final_indices = torch.tensor(final_indices)\n",
    "\n",
    "    times = torch.linspace(1, X_times.size(1), X_times.size(1))\n",
    "\n",
    "    (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "     test_final_index, _) = common.preprocess_data(times, X_times, y, final_indices, append_times=True,\n",
    "                                                   append_intensity=time_intensity)\n",
    "    if static_intensity:\n",
    "        X_static_ = X_static[:, :-2]\n",
    "        X_static_ = common.normalise_data(X_static_, y)\n",
    "        X_static = torch.cat([X_static_, X_static[:, -2:]], dim=1)\n",
    "    else:\n",
    "        X_static = common.normalise_data(X_static, y)\n",
    "    train_X_static, val_X_static, test_X_static = common.split_data(X_static, y)\n",
    "    train_coeffs = (*train_coeffs, train_X_static)\n",
    "    val_coeffs = (*val_coeffs, val_X_static)\n",
    "    test_coeffs = (*test_coeffs, test_X_static)\n",
    "\n",
    "    return (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "            test_final_index)\n",
    "\n",
    "\n",
    "def get_data(static_intensity, time_intensity, batch_size):\n",
    "    base_base_loc = here / 'processed_data'\n",
    "    loc = base_base_loc / ('sepsis' + ('_staticintensity' if static_intensity else '_nostaticintensity') + ('_timeintensity' if time_intensity else '_notimeintensity'))\n",
    "    if os.path.exists(loc):\n",
    "        tensors = common.load_data(loc)\n",
    "        times = tensors['times']\n",
    "        train_coeffs = tensors['train_a'], tensors['train_b'], tensors['train_c'], tensors['train_d'], tensors['train_static']\n",
    "        val_coeffs = tensors['val_a'], tensors['val_b'], tensors['val_c'], tensors['val_d'], tensors['val_static']\n",
    "        test_coeffs = tensors['test_a'], tensors['test_b'], tensors['test_c'], tensors['test_d'], tensors['test_static']\n",
    "        train_y = tensors['train_y']\n",
    "        val_y = tensors['val_y']\n",
    "        test_y = tensors['test_y']\n",
    "        train_final_index = tensors['train_final_index']\n",
    "        val_final_index = tensors['val_final_index']\n",
    "        test_final_index = tensors['test_final_index']\n",
    "    else:\n",
    "        download()\n",
    "        (times, train_coeffs, val_coeffs, test_coeffs, train_y, val_y, test_y, train_final_index, val_final_index,\n",
    "         test_final_index) = _process_data(static_intensity, time_intensity)\n",
    "        if not os.path.exists(base_base_loc):\n",
    "            os.mkdir(base_base_loc)\n",
    "        if not os.path.exists(loc):\n",
    "            os.mkdir(loc)\n",
    "        common.save_data(loc, times=times,\n",
    "                         train_a=train_coeffs[0], train_b=train_coeffs[1], train_c=train_coeffs[2],\n",
    "                         train_d=train_coeffs[3], train_static=train_coeffs[4],\n",
    "                         val_a=val_coeffs[0], val_b=val_coeffs[1], val_c=val_coeffs[2], val_d=val_coeffs[3],\n",
    "                         val_static=val_coeffs[4],\n",
    "                         test_a=test_coeffs[0], test_b=test_coeffs[1], test_c=test_coeffs[2], test_d=test_coeffs[3],\n",
    "                         test_static=test_coeffs[4],\n",
    "                         train_y=train_y, val_y=val_y, test_y=test_y, train_final_index=train_final_index,\n",
    "                         val_final_index=val_final_index, test_final_index=test_final_index)\n",
    "\n",
    "    times, train_dataloader, val_dataloader, test_dataloader = common.wrap_data(times, train_coeffs, val_coeffs,\n",
    "                                                                                test_coeffs, train_y, val_y, test_y,\n",
    "                                                                                train_final_index, val_final_index,\n",
    "                                                                                test_final_index, 'cpu',\n",
    "                                                                                batch_size=batch_size)\n",
    "\n",
    "    return times, train_dataloader, val_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5091a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_weight_regularisation(loss_fn, regularise_parameters, scaling=0.03):\n",
    "    def new_loss_fn(pred_y, true_y):\n",
    "        total_loss = loss_fn(pred_y, true_y)\n",
    "        for parameter in regularise_parameters.parameters():\n",
    "            if parameter.requires_grad:\n",
    "                total_loss = total_loss + scaling * parameter.norm()\n",
    "        return total_loss\n",
    "    return new_loss_fn\n",
    "\n",
    "\n",
    "class _SqueezeEnd(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(_SqueezeEnd, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs).squeeze(-1)\n",
    "\n",
    "\n",
    "def _count_parameters(model):\n",
    "    \"\"\"Counts the number of parameters in a model.\"\"\"\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad_)\n",
    "\n",
    "\n",
    "class _AttrDict(dict):\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return self[item]\n",
    "\n",
    "\n",
    "def _evaluate_metrics(dataloader, model, times, loss_fn, num_classes, device, kwargs):\n",
    "    with torch.no_grad():\n",
    "        total_accuracy = 0\n",
    "        total_confusion = torch.zeros(num_classes, num_classes).numpy()  # occurs all too often\n",
    "        total_dataset_size = 0\n",
    "        total_loss = 0\n",
    "        true_y_cpus = []\n",
    "        pred_y_cpus = []\n",
    "\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            *coeffs, true_y, lengths = batch\n",
    "            batch_size = true_y.size(0)\n",
    "            pred_y = model(times, coeffs, lengths, **kwargs)\n",
    "\n",
    "            if num_classes == 2:\n",
    "                thresholded_y = (pred_y > 0).to(true_y.dtype)\n",
    "            else:\n",
    "                thresholded_y = torch.argmax(pred_y, dim=1)\n",
    "            true_y_cpu = true_y.detach().cpu()\n",
    "            pred_y_cpu = pred_y.detach().cpu()\n",
    "            if num_classes == 2:\n",
    "                # Assume that our datasets aren't so large that this breaks\n",
    "                true_y_cpus.append(true_y_cpu)\n",
    "                pred_y_cpus.append(pred_y_cpu)\n",
    "            thresholded_y_cpu = thresholded_y.detach().cpu()\n",
    "\n",
    "            total_accuracy += (thresholded_y == true_y).sum().to(pred_y.dtype)\n",
    "            total_confusion += sklearn.metrics.confusion_matrix(true_y_cpu, thresholded_y_cpu,\n",
    "                                                                labels=range(num_classes))\n",
    "            total_dataset_size += batch_size\n",
    "            total_loss += loss_fn(pred_y, true_y) * batch_size\n",
    "\n",
    "        total_loss /= total_dataset_size  # assume 'mean' reduction in the loss function\n",
    "        total_accuracy /= total_dataset_size\n",
    "        metrics = _AttrDict(accuracy=total_accuracy.item(), confusion=total_confusion, dataset_size=total_dataset_size,\n",
    "                            loss=total_loss.item())\n",
    "\n",
    "        if num_classes == 2:\n",
    "            true_y_cpus = torch.cat(true_y_cpus, dim=0)\n",
    "            pred_y_cpus = torch.cat(pred_y_cpus, dim=0)\n",
    "            metrics.auroc = sklearn.metrics.roc_auc_score(true_y_cpus, pred_y_cpus)\n",
    "            metrics.average_precision = sklearn.metrics.average_precision_score(true_y_cpus, pred_y_cpus)\n",
    "        return metrics\n",
    "\n",
    "\n",
    "class _SuppressAssertions:\n",
    "    def __init__(self, tqdm_range):\n",
    "        self.tqdm_range = tqdm_range\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if exc_type is AssertionError:\n",
    "            self.tqdm_range.write('Caught AssertionError: ' + str(exc_val))\n",
    "            return True\n",
    "\n",
    "\n",
    "def _train_loop(train_dataloader, val_dataloader, model, times, optimizer, loss_fn, max_epochs, num_classes, device,\n",
    "                kwargs, step_mode):\n",
    "    model.train()\n",
    "    best_model = model\n",
    "    best_train_loss = math.inf\n",
    "    best_train_accuracy = 0\n",
    "    best_val_accuracy = 0\n",
    "    best_train_accuracy_epoch = 0\n",
    "    best_train_loss_epoch = 0\n",
    "    history = []\n",
    "    breaking = False\n",
    "\n",
    "    if step_mode:\n",
    "        epoch_per_metric = 10\n",
    "        plateau_terminate = 100\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)\n",
    "    else:\n",
    "        epoch_per_metric = 10\n",
    "        plateau_terminate = 50\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, mode='max')\n",
    "\n",
    "    tqdm_range = tqdm.tqdm(range(max_epochs))\n",
    "    tqdm_range.write('Starting training for model:\\n\\n' + str(model) + '\\n\\n')\n",
    "    for epoch in tqdm_range:\n",
    "        if breaking:\n",
    "            break\n",
    "        for batch in train_dataloader:\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            if breaking:\n",
    "                break\n",
    "            with _SuppressAssertions(tqdm_range):\n",
    "                *train_coeffs, train_y, lengths = batch\n",
    "                pred_y = model(times, train_coeffs, lengths, **kwargs)\n",
    "                loss = loss_fn(pred_y, train_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        if epoch % epoch_per_metric == 0 or epoch == max_epochs - 1:\n",
    "            model.eval()\n",
    "            train_metrics = _evaluate_metrics(train_dataloader, model, times, loss_fn, num_classes, device, kwargs)\n",
    "            val_metrics = _evaluate_metrics(val_dataloader, model, times, loss_fn, num_classes, device, kwargs)\n",
    "            model.train()\n",
    "\n",
    "            if train_metrics.loss * 1.0001 < best_train_loss:\n",
    "                best_train_loss = train_metrics.loss\n",
    "                best_train_loss_epoch = epoch\n",
    "\n",
    "            if train_metrics.accuracy > best_train_accuracy * 1.001:\n",
    "                best_train_accuracy = train_metrics.accuracy\n",
    "                best_train_accuracy_epoch = epoch\n",
    "\n",
    "            if val_metrics.accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_metrics.accuracy\n",
    "                del best_model  # so that we don't have three copies of a model simultaneously\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            tqdm_range.write('Epoch: {}  Train loss: {:.3}  Train accuracy: {:.3}  Val loss: {:.3}  '\n",
    "                             'Val accuracy: {:.3}'\n",
    "                             ''.format(epoch, train_metrics.loss, train_metrics.accuracy, val_metrics.loss,\n",
    "                                       val_metrics.accuracy))\n",
    "            if step_mode:\n",
    "                scheduler.step(train_metrics.loss)\n",
    "            else:\n",
    "                scheduler.step(val_metrics.accuracy)\n",
    "            history.append(_AttrDict(epoch=epoch, train_metrics=train_metrics, val_metrics=val_metrics))\n",
    "\n",
    "            if epoch > best_train_loss_epoch + plateau_terminate:\n",
    "                tqdm_range.write('Breaking because of no improvement in training loss for {} epochs.'\n",
    "                                 ''.format(plateau_terminate))\n",
    "                breaking = True\n",
    "            if epoch > best_train_accuracy_epoch + plateau_terminate:\n",
    "                tqdm_range.write('Breaking because of no improvement in training accuracy for {} epochs.'\n",
    "                                 ''.format(plateau_terminate))\n",
    "                breaking = True\n",
    "\n",
    "    for parameter, best_parameter in zip(model.parameters(), best_model.parameters()):\n",
    "        parameter.data = best_parameter.data\n",
    "    return history\n",
    "\n",
    "\n",
    "class _TensorEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, (torch.Tensor, np.ndarray)):\n",
    "            return o.tolist()\n",
    "        else:\n",
    "            super(_TensorEncoder, self).default(o)\n",
    "\n",
    "\n",
    "def _save_results(name, result):\n",
    "    loc = here / 'results' / name\n",
    "    if not os.path.exists(loc):\n",
    "        os.mkdir(loc)\n",
    "    num = -1\n",
    "    for filename in os.listdir(loc):\n",
    "        try:\n",
    "            num = max(num, int(filename))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    result_to_save = result.copy()\n",
    "    del result_to_save['train_dataloader']\n",
    "    del result_to_save['val_dataloader']\n",
    "    del result_to_save['test_dataloader']\n",
    "    result_to_save['model'] = str(result_to_save['model'])\n",
    "\n",
    "    num += 1\n",
    "    with open(loc / str(num), 'w') as f:\n",
    "        json.dump(result_to_save, f, cls=_TensorEncoder)\n",
    "\n",
    "\n",
    "def cmain(name, times, train_dataloader, val_dataloader, test_dataloader, device, make_model, num_classes, max_epochs,\n",
    "         lr, kwargs, step_mode, pos_weight=torch.tensor(1)):\n",
    "    times = times.to(device)\n",
    "    if device != 'cpu':\n",
    "        torch.cuda.reset_max_memory_allocated(device)\n",
    "        baseline_memory = torch.cuda.memory_allocated(device)\n",
    "    else:\n",
    "        baseline_memory = None\n",
    "\n",
    "    model, regularise_parameters = make_model()\n",
    "    if num_classes == 2:\n",
    "        model = _SqueezeEnd(model)\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    else:\n",
    "        loss_fn = torch.nn.functional.cross_entropy\n",
    "    loss_fn = _add_weight_regularisation(loss_fn, regularise_parameters)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = _train_loop(train_dataloader, val_dataloader, model, times, optimizer, loss_fn, max_epochs,\n",
    "                          num_classes, device, kwargs, step_mode)\n",
    "\n",
    "    model.eval()\n",
    "    train_metrics = _evaluate_metrics(train_dataloader, model, times, loss_fn, num_classes, device, kwargs)\n",
    "    val_metrics = _evaluate_metrics(val_dataloader, model, times, loss_fn, num_classes, device, kwargs)\n",
    "    test_metrics = _evaluate_metrics(test_dataloader, model, times, loss_fn, num_classes, device, kwargs)\n",
    "\n",
    "    if device != 'cpu':\n",
    "        memory_usage = torch.cuda.max_memory_allocated(device) - baseline_memory\n",
    "    else:\n",
    "        memory_usage = None\n",
    "\n",
    "    result = _AttrDict(times=times,\n",
    "                       memory_usage=memory_usage,\n",
    "                       baseline_memory=baseline_memory,\n",
    "                       num_classes=num_classes,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       val_dataloader=val_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       model=model.to('cpu'),\n",
    "                       parameters=_count_parameters(model),\n",
    "                       history=history,\n",
    "                       train_metrics=train_metrics,\n",
    "                       val_metrics=val_metrics,\n",
    "                       test_metrics=test_metrics)\n",
    "    if name is not None:\n",
    "        _save_results(name, result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cmake_model(name, input_channels, output_channels, hidden_channels, hidden_hidden_channels, num_hidden_layers,\n",
    "               use_intensity, initial):\n",
    "    if name == 'ncde':\n",
    "        def make_model():\n",
    "            vector_field = models.FinalTanh(input_channels=input_channels, hidden_channels=hidden_channels,\n",
    "                                            hidden_hidden_channels=hidden_hidden_channels,\n",
    "                                            num_hidden_layers=num_hidden_layers)\n",
    "            model = models.NeuralCDE(func=vector_field, input_channels=input_channels, hidden_channels=hidden_channels,\n",
    "                                     output_channels=output_channels, initial=initial)\n",
    "            return model, vector_field\n",
    "    elif name == 'gruode':\n",
    "        def make_model():\n",
    "            vector_field = models.GRU_ODE(input_channels=input_channels, hidden_channels=hidden_channels)\n",
    "            model = models.NeuralCDE(func=vector_field, input_channels=input_channels,\n",
    "                                     hidden_channels=hidden_channels, output_channels=output_channels, initial=initial)\n",
    "            return model, vector_field\n",
    "    elif name == 'dt':\n",
    "        def make_model():\n",
    "            model = models.GRU_dt(input_channels=input_channels, hidden_channels=hidden_channels,\n",
    "                                  output_channels=output_channels, use_intensity=use_intensity)\n",
    "            return model, model\n",
    "    elif name == 'decay':\n",
    "        def make_model():\n",
    "            model = models.GRU_D(input_channels=input_channels, hidden_channels=hidden_channels,\n",
    "                                 output_channels=output_channels, use_intensity=use_intensity)\n",
    "            return model, model\n",
    "    elif name == 'odernn':\n",
    "        def make_model():\n",
    "            model = models.ODERNN(input_channels=input_channels, hidden_channels=hidden_channels,\n",
    "                                  hidden_hidden_channels=hidden_hidden_channels, num_hidden_layers=num_hidden_layers,\n",
    "                                  output_channels=output_channels, use_intensity=use_intensity)\n",
    "            return model, model\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognised model name {}. Valid names are 'ncde', 'gruode', 'dt', 'decay' and 'odernn'.\"\n",
    "                         \"\".format(name))\n",
    "    return make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400ece0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fa126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(device='cuda', max_epochs=200, *,                                        # training parameters\n",
    "         model_name, hidden_channels, hidden_hidden_channels, num_hidden_layers,  # model parameters\n",
    "         dry_run=False,\n",
    "         **kwargs):                                                               # kwargs passed on to cdeint\n",
    "\n",
    "    batch_size = 1024\n",
    "    lr = 0.00005 * (batch_size / 32)\n",
    "\n",
    "    intensity_data = True if model_name in ('odernn', 'dt', 'decay') else False\n",
    "    times, train_dataloader, val_dataloader, test_dataloader = get_data(intensity_data,\n",
    "                                                                                                 batch_size)\n",
    "    input_channels = 1 + (1 + intensity_data) * 20\n",
    "\n",
    "    make_model = cmake_model(model_name, input_channels, 10, hidden_channels, hidden_hidden_channels,\n",
    "                                   num_hidden_layers, use_intensity=False, initial=True)\n",
    "\n",
    "    def new_make_model():\n",
    "        model, regularise = make_model()\n",
    "        model.linear.weight.register_hook(lambda grad: 100 * grad)\n",
    "        model.linear.bias.register_hook(lambda grad: 100 * grad)\n",
    "        return model, regularise\n",
    "\n",
    "    name = None if dry_run else 'speech_commands'\n",
    "    num_classes = 10\n",
    "    return cmain(name, times, train_dataloader, val_dataloader, test_dataloader, device, new_make_model,\n",
    "                       num_classes, max_epochs, lr, kwargs, step_mode=True)\n",
    "\n",
    "\n",
    "def run_all(device, model_names=('ncde', 'odernn', 'dt', 'decay', 'gruode')):\n",
    "    model_kwargs = dict(ncde=dict(hidden_channels=90, hidden_hidden_channels=40, num_hidden_layers=4),\n",
    "                        odernn=dict(hidden_channels=128, hidden_hidden_channels=64, num_hidden_layers=4),\n",
    "                        dt=dict(hidden_channels=160, hidden_hidden_channels=None, num_hidden_layers=None),\n",
    "                        decay=dict(hidden_channels=160, hidden_hidden_channels=None, num_hidden_layers=None),\n",
    "                        gruode=dict(hidden_channels=160, hidden_hidden_channels=None, num_hidden_layers=None))\n",
    "    for model_name in model_names:\n",
    "        # Hyperparameters selected as what ODE-RNN did best with.\n",
    "        for _ in range(5):\n",
    "            main(device, model_name=model_name, **model_kwargs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e25441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_get data   function\n",
      "Download function\n",
      "_process data  function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dungvt/.conda/envs/ml/lib/python3.9/site-packages/torchaudio/functional/functional.py:432: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (101) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run the speechs_commands dataset á anh\n",
    "run_all(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the result\n",
    "def _get(filename, metric):\n",
    "    with open(filename, 'r') as f:\n",
    "        content = json.load(f)\n",
    "    if metric == 'accuracy':\n",
    "        metric_value = content['test_metrics']['accuracy']\n",
    "    elif metric == 'auroc':\n",
    "        metric_value = content['test_metrics']['auroc']\n",
    "    elif metric == 'history':\n",
    "        metric_value = content['history']\n",
    "    else:\n",
    "        raise ValueError\n",
    "    # NeuralCDE must come after GRU_ODE\n",
    "    for model_name in ('GRU_ODE', 'GRU_dt', 'GRU_decay', 'GRU_D', 'NeuralCDE', 'ODERNN'):\n",
    "        if model_name in content['model']:\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "    parameters = content['parameters']\n",
    "    memory_usage = content['memory_usage']\n",
    "    return metric_value, model_name, parameters, memory_usage\n",
    "\n",
    "\n",
    "def plot_history(foldername, metric='accuracy'):\n",
    "    foldername = pathlib.Path('results') / foldername\n",
    "    results_for_each_run = co.defaultdict(list)\n",
    "    for filename in os.listdir(foldername):\n",
    "        history, model_name, _, _ = _get(foldername / filename, 'history')\n",
    "        times = []\n",
    "        values = []\n",
    "        for entry in history:\n",
    "            times.append(int(entry['epoch']))\n",
    "            value = float(entry['val_metrics'][metric])\n",
    "            if metric == 'accuracy':\n",
    "                value *= 100\n",
    "            values.append(value)\n",
    "        results_for_each_run[model_name].append((times, values))\n",
    "    colours = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "    model_names = ('NeuralCDE', 'ODERNN', 'GRU_D', 'GRU_dt', 'GRU_ODE')\n",
    "    assert set(results_for_each_run.keys()) == set(model_names)\n",
    "    # Ensures the order of plotting\n",
    "    for colour, model_name in zip(colours, model_names):\n",
    "        model_results = results_for_each_run[model_name]\n",
    "        all_times = set()\n",
    "        for times, _ in model_results:\n",
    "            all_times.update(times)\n",
    "        all_times = sorted(list(all_times))\n",
    "        all_values = [[] for _ in range(len(all_times))]\n",
    "        for times, values in model_results:\n",
    "            # The times we measured at should be the same for every run, it's just that some runs finished earlier than\n",
    "            # others\n",
    "            assert times == all_times[:len(times)]\n",
    "            for i, entry in enumerate(values):\n",
    "                all_values[i].append(entry)\n",
    "        means = [statistics.mean(entry) for entry in all_values]\n",
    "        stds = [statistics.stdev(entry) if len(entry) > 1 else 0 for entry in all_values]\n",
    "        plt.plot(all_times, means, label=model_name, color=colour)\n",
    "        plt.fill_between(all_times,\n",
    "                         [mean + 0.2 * std for mean, std in zip(means, stds)],\n",
    "                         [mean - 0.2 * std for mean, std in zip(means, stds)],\n",
    "                         color=colour,\n",
    "                         alpha=0.5)\n",
    "    plt.title('Validation ' + str(metric) + ' during training')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy %' if metric == 'accuracy' else str(metric).capitalize())\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def table(foldername, metric):\n",
    "    assert metric in ('accuracy', 'auroc')\n",
    "    foldername = pathlib.Path('results') / foldername\n",
    "    results = co.defaultdict(list)\n",
    "    parameter_results = {}\n",
    "    memory_results = {}\n",
    "    for filename in os.listdir(foldername):\n",
    "        metric_value, model_name, parameters, memory_usage = _get(foldername / filename, metric)\n",
    "        results[model_name].append(metric_value)\n",
    "        parameter_results[model_name] = parameters\n",
    "        memory_results[model_name] = memory_usage / (1024 ** 2)\n",
    "    min_result_length = min(len(result) for result in results.values())\n",
    "    sorted_results = []\n",
    "    for key, value in results.items():\n",
    "        sorted_results.append((key, torch.tensor(value)))\n",
    "    sorted_results.sort(key=lambda x: -x[1].mean())\n",
    "    print(\"Num samples: \" + str(min_result_length))\n",
    "    for key, value in sorted_results:\n",
    "        value = value[:min_result_length]\n",
    "        print(\"{:9}: min: {:.3f} mean: {:.3f} median: {:.3f} max: {:.3f} std:{:.3f} | mem: {:.3f}MB param: {} \"\n",
    "              \"\".format(key, value.min(), value.mean(), value.median(), value.max(), value.std(),\n",
    "                        memory_results[key], parameter_results[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
